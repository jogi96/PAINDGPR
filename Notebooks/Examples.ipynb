{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d76066c3",
   "metadata": {},
   "source": [
    "## Testing if Packages are working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c54a1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 c:\\pythonad\\PAIND_Datreader\\bus.jpg: 640x480 4 persons, 1 bus, 142.1ms\n",
      "Speed: 30.0ms preprocess, 142.1ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "# Modell laden (z. B. kleine Version)\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Test-Inferenz auf einem Beispielbild\n",
    "results = model(\"https://ultralytics.com/images/bus.jpg\")\n",
    "results[0].show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c636b",
   "metadata": {},
   "source": [
    "## Testing Model with Dataset from Roboflow on impbautech AG data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3780d099",
   "metadata": {},
   "source": [
    "### Manual testing directly with yolo model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00177dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f21a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\vscode\\PAIND\\Data\\Testdata\\pictures\\frame_0.jpg: 448x640 2 hyperbolas, 75.0ms\n",
      "Speed: 2.3ms preprocess, 75.0ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mC:\\vscode\\PAIND\\Notebooks\\runs\\detect\\predict\u001b[0m\n",
      "<class 'ultralytics.engine.results.Results'>\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(YOLO_MODEL_DIR)  # load a custom model\n",
    "results = model.predict(TEST_PIC_DIR / \"frame_0.jpg\",save=True, conf=0.2)  # predict on an image\n",
    "print(type(results[0]))  # print results to terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3727796",
   "metadata": {},
   "source": [
    "## Testing with Predictor Class "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26de7d74",
   "metadata": {},
   "source": [
    "### Import configfile for paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59ac47ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315f7afe",
   "metadata": {},
   "source": [
    "### import Predictor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05c598d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pipeline.Predictor import Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57544bb",
   "metadata": {},
   "source": [
    "### Making Prediction and extract Bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a4452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(model_path=YOLO_MODEL_DIR,conf =0.2, x_max=11, y_max=20)\n",
    "#bboxes = predictor.extract_bboxes(r\"C:\\Users\\Joris Gisler\\OneDrive - Hochschule Luzern\\Studium\\HS25\\PAIND\\Daten\\Testdata\\frame_0.jpg\")\n",
    "\n",
    "#print(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e1ebe9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "c:\\vscode\\PAINDGPR\\Data\\Testdata\\pictures\\frame_0.jpg does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m## getting the vertex of the bounding boxes\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m scaled_verteces, verticels, bboxes = \u001b[43mpredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_and_scale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTEST_PIC_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mframe_0.jpg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#print(verticels)\u001b[39;00m\n\u001b[32m      4\u001b[39m predictor.plot_detected_points(TEST_PIC_DIR / \u001b[33m\"\u001b[39m\u001b[33mframe_0.jpg\u001b[39m\u001b[33m\"\u001b[39m, verticels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vscode\\PAINDGPR\\Pipeline\\Predictor.py:31\u001b[39m, in \u001b[36mPredictor.predict_and_scale\u001b[39m\u001b[34m(self, image)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_and_scale\u001b[39m(\u001b[38;5;28mself\u001b[39m,image :\u001b[38;5;28mstr\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     bboxes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mextract_bboxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     verticels = \u001b[38;5;28mself\u001b[39m.get_vertex(bboxes)\n\u001b[32m     34\u001b[39m     scaled_verteces = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vscode\\PAINDGPR\\Pipeline\\Predictor.py:14\u001b[39m, in \u001b[36mPredictor.extract_bboxes\u001b[39m\u001b[34m(self, image)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_bboxes\u001b[39m(\u001b[38;5;28mself\u001b[39m, image)-> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     bboxes = []\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gijo\\AppData\\Local\\anaconda3\\envs\\PAINDHS25\\Lib\\site-packages\\ultralytics\\engine\\model.py:557\u001b[39m, in \u001b[36mModel.predict\u001b[39m\u001b[34m(self, source, stream, predictor, **kwargs)\u001b[39m\n\u001b[32m    555\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.predictor, \u001b[33m\"\u001b[39m\u001b[33mset_prompts\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[32m    556\u001b[39m     \u001b[38;5;28mself\u001b[39m.predictor.set_prompts(prompts)\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predictor.predict_cli(source=source) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gijo\\AppData\\Local\\anaconda3\\envs\\PAINDHS25\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:229\u001b[39m, in \u001b[36mBasePredictor.__call__\u001b[39m\u001b[34m(self, source, model, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    227\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream_inference(source, model, *args, **kwargs)\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gijo\\AppData\\Local\\anaconda3\\envs\\PAINDHS25\\Lib\\site-packages\\torch\\utils\\_contextlib.py:38\u001b[39m, in \u001b[36m_wrap_generator.<locals>.generator_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     36\u001b[39m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         response = \u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     41\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     42\u001b[39m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gijo\\AppData\\Local\\anaconda3\\envs\\PAINDHS25\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:306\u001b[39m, in \u001b[36mBasePredictor.stream_inference\u001b[39m\u001b[34m(self, source, model, *args, **kwargs)\u001b[39m\n\u001b[32m    302\u001b[39m     \u001b[38;5;28mself\u001b[39m.setup_model(model)\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:  \u001b[38;5;66;03m# for thread-safe inference\u001b[39;00m\n\u001b[32m    305\u001b[39m     \u001b[38;5;66;03m# Setup source every time predict is called\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msetup_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    308\u001b[39m     \u001b[38;5;66;03m# Check if save_dir/ label file exists\u001b[39;00m\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save_txt:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gijo\\AppData\\Local\\anaconda3\\envs\\PAINDHS25\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:261\u001b[39m, in \u001b[36mBasePredictor.setup_source\u001b[39m\u001b[34m(self, source)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    254\u001b[39m \u001b[33;03mSet up source and inference mode.\u001b[39;00m\n\u001b[32m    255\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    258\u001b[39m \u001b[33;03m        Source for inference.\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28mself\u001b[39m.imgsz = check_imgsz(\u001b[38;5;28mself\u001b[39m.args.imgsz, stride=\u001b[38;5;28mself\u001b[39m.model.stride, min_dim=\u001b[32m2\u001b[39m)  \u001b[38;5;66;03m# check image size\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m \u001b[38;5;28mself\u001b[39m.dataset = \u001b[43mload_inference_source\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvid_stride\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvid_stride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[38;5;28mself\u001b[39m.source_type = \u001b[38;5;28mself\u001b[39m.dataset.source_type\n\u001b[32m    269\u001b[39m long_sequence = (\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m.source_type.stream\n\u001b[32m    271\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.source_type.screenshot\n\u001b[32m    272\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset) > \u001b[32m1000\u001b[39m  \u001b[38;5;66;03m# many images\u001b[39;00m\n\u001b[32m    273\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33mvideo_flag\u001b[39m\u001b[33m\"\u001b[39m, [\u001b[38;5;28;01mFalse\u001b[39;00m]))\n\u001b[32m    274\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gijo\\AppData\\Local\\anaconda3\\envs\\PAINDHS25\\Lib\\site-packages\\ultralytics\\data\\build.py:310\u001b[39m, in \u001b[36mload_inference_source\u001b[39m\u001b[34m(source, batch, vid_stride, buffer, channels)\u001b[39m\n\u001b[32m    308\u001b[39m     dataset = LoadPilAndNumpy(source, channels=channels)\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     dataset = \u001b[43mLoadImagesAndVideos\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvid_stride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvid_stride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[38;5;66;03m# Attach source types to the dataset\u001b[39;00m\n\u001b[32m    313\u001b[39m \u001b[38;5;28msetattr\u001b[39m(dataset, \u001b[33m\"\u001b[39m\u001b[33msource_type\u001b[39m\u001b[33m\"\u001b[39m, source_type)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gijo\\AppData\\Local\\anaconda3\\envs\\PAINDHS25\\Lib\\site-packages\\ultralytics\\data\\loaders.py:376\u001b[39m, in \u001b[36mLoadImagesAndVideos.__init__\u001b[39m\u001b[34m(self, path, batch, vid_stride, channels)\u001b[39m\n\u001b[32m    374\u001b[39m         files.append(\u001b[38;5;28mstr\u001b[39m((parent / p).absolute()))  \u001b[38;5;66;03m# files (relative to *.txt file parent)\u001b[39;00m\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not exist\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    378\u001b[39m \u001b[38;5;66;03m# Define files as images or videos\u001b[39;00m\n\u001b[32m    379\u001b[39m images, videos = [], []\n",
      "\u001b[31mFileNotFoundError\u001b[39m: c:\\vscode\\PAINDGPR\\Data\\Testdata\\pictures\\frame_0.jpg does not exist"
     ]
    }
   ],
   "source": [
    "## getting the vertex of the bounding boxes\n",
    "scaled_verteces, verticels, bboxes = predictor.predict_and_scale(TEST_PIC_DIR / \"frame_0.jpg\")\n",
    "#print(verticels)\n",
    "predictor.plot_detected_points(TEST_PIC_DIR / \"frame_0.jpg\", verticels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f128de",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d46c5d01",
   "metadata": {},
   "source": [
    "## Testing Video Cutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5d5754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Videocutter.Video_cutter import Video_Cutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5990c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original video FPS: 24.0\n",
      "Extracting every 6th frame (~4 FPS)\n",
      "72 Frames saved in 'C:\\Users\\Joris Gisler\\OneDrive - Hochschule Luzern\\Studium\\HS25\\PAIND\\Daten\\Testdata'\n"
     ]
    }
   ],
   "source": [
    "cutter = Video_Cutter(video_path=r\"C:\\Users\\Joris Gisler\\OneDrive - Hochschule Luzern\\Studium\\HS25\\PAIND\\Daten\\Videos\\EG_quer_y-cut (2).mpg\", output_path=r\"C:\\Users\\Joris Gisler\\OneDrive - Hochschule Luzern\\Studium\\HS25\\PAIND\\Daten\\Testdata\", target_fps=4)\n",
    "cutter.cut_video()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PAINDHS25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
